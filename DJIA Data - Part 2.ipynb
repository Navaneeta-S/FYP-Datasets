{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92e15866",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "import string\n",
    "import nltk\n",
    "import torch\n",
    "import pysentiment2 as ps\n",
    "import tensorflow as tf\n",
    "import xgboost as xgb\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from textblob import TextBlob\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.layers import Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5dce9250",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>BERT_Positive</th>\n",
       "      <th>BERT_Negative</th>\n",
       "      <th>...</th>\n",
       "      <th>H_Aggregate</th>\n",
       "      <th>LM_Positive</th>\n",
       "      <th>LM_Negative</th>\n",
       "      <th>LM_Aggregate</th>\n",
       "      <th>Positive_Score</th>\n",
       "      <th>Negative_Score</th>\n",
       "      <th>Neutral_Score</th>\n",
       "      <th>Compound_Score</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2016-07-01</td>\n",
       "      <td>0.966790</td>\n",
       "      <td>0.970024</td>\n",
       "      <td>0.969867</td>\n",
       "      <td>0.969145</td>\n",
       "      <td>0.110651</td>\n",
       "      <td>0.969145</td>\n",
       "      <td>0.588598</td>\n",
       "      <td>0.411402</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.315789</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-0.666667</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.302</td>\n",
       "      <td>0.631</td>\n",
       "      <td>-0.9987</td>\n",
       "      <td>-0.006564</td>\n",
       "      <td>0.316409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2016-06-30</td>\n",
       "      <td>0.948819</td>\n",
       "      <td>0.963859</td>\n",
       "      <td>0.952488</td>\n",
       "      <td>0.967498</td>\n",
       "      <td>0.186974</td>\n",
       "      <td>0.967498</td>\n",
       "      <td>0.585330</td>\n",
       "      <td>0.414670</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.388889</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-0.636364</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.297</td>\n",
       "      <td>0.616</td>\n",
       "      <td>-0.9982</td>\n",
       "      <td>0.018968</td>\n",
       "      <td>0.377540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2016-06-29</td>\n",
       "      <td>0.927002</td>\n",
       "      <td>0.944437</td>\n",
       "      <td>0.930817</td>\n",
       "      <td>0.947497</td>\n",
       "      <td>0.146990</td>\n",
       "      <td>0.947497</td>\n",
       "      <td>0.578757</td>\n",
       "      <td>0.421243</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.400000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-0.714286</td>\n",
       "      <td>0.123</td>\n",
       "      <td>0.260</td>\n",
       "      <td>0.617</td>\n",
       "      <td>-0.9943</td>\n",
       "      <td>0.050125</td>\n",
       "      <td>0.387107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2016-06-28</td>\n",
       "      <td>0.904440</td>\n",
       "      <td>0.919115</td>\n",
       "      <td>0.908321</td>\n",
       "      <td>0.923277</td>\n",
       "      <td>0.155707</td>\n",
       "      <td>0.923277</td>\n",
       "      <td>0.615913</td>\n",
       "      <td>0.384087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>-0.692308</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.172</td>\n",
       "      <td>0.685</td>\n",
       "      <td>-0.9424</td>\n",
       "      <td>0.039465</td>\n",
       "      <td>0.329909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2016-06-27</td>\n",
       "      <td>0.918436</td>\n",
       "      <td>0.914433</td>\n",
       "      <td>0.897524</td>\n",
       "      <td>0.900373</td>\n",
       "      <td>0.195541</td>\n",
       "      <td>0.900373</td>\n",
       "      <td>0.618050</td>\n",
       "      <td>0.381950</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.263158</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.600000</td>\n",
       "      <td>0.117</td>\n",
       "      <td>0.219</td>\n",
       "      <td>0.664</td>\n",
       "      <td>-0.9839</td>\n",
       "      <td>-0.006098</td>\n",
       "      <td>0.349394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1984</th>\n",
       "      <td>1984</td>\n",
       "      <td>2008-08-14</td>\n",
       "      <td>0.423610</td>\n",
       "      <td>0.430233</td>\n",
       "      <td>0.422020</td>\n",
       "      <td>0.430832</td>\n",
       "      <td>0.227123</td>\n",
       "      <td>0.430832</td>\n",
       "      <td>0.590350</td>\n",
       "      <td>0.409650</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.083333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.121</td>\n",
       "      <td>0.227</td>\n",
       "      <td>0.652</td>\n",
       "      <td>-0.9805</td>\n",
       "      <td>0.024498</td>\n",
       "      <td>0.328388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1985</th>\n",
       "      <td>1985</td>\n",
       "      <td>2008-08-13</td>\n",
       "      <td>0.432170</td>\n",
       "      <td>0.422975</td>\n",
       "      <td>0.422228</td>\n",
       "      <td>0.423779</td>\n",
       "      <td>0.261271</td>\n",
       "      <td>0.423779</td>\n",
       "      <td>0.578226</td>\n",
       "      <td>0.421774</td>\n",
       "      <td>...</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.600000</td>\n",
       "      <td>0.093</td>\n",
       "      <td>0.197</td>\n",
       "      <td>0.709</td>\n",
       "      <td>-0.9758</td>\n",
       "      <td>0.016061</td>\n",
       "      <td>0.370301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1986</th>\n",
       "      <td>1986</td>\n",
       "      <td>2008-08-12</td>\n",
       "      <td>0.444822</td>\n",
       "      <td>0.435737</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.433087</td>\n",
       "      <td>0.247828</td>\n",
       "      <td>0.433087</td>\n",
       "      <td>0.508867</td>\n",
       "      <td>0.491133</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.310345</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.093</td>\n",
       "      <td>0.251</td>\n",
       "      <td>0.656</td>\n",
       "      <td>-0.9931</td>\n",
       "      <td>-0.036307</td>\n",
       "      <td>0.531229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1987</th>\n",
       "      <td>1987</td>\n",
       "      <td>2008-08-11</td>\n",
       "      <td>0.440401</td>\n",
       "      <td>0.443018</td>\n",
       "      <td>0.441053</td>\n",
       "      <td>0.444976</td>\n",
       "      <td>0.262232</td>\n",
       "      <td>0.444976</td>\n",
       "      <td>0.622814</td>\n",
       "      <td>0.377186</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.250000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-0.600000</td>\n",
       "      <td>0.092</td>\n",
       "      <td>0.273</td>\n",
       "      <td>0.635</td>\n",
       "      <td>-0.9888</td>\n",
       "      <td>0.079866</td>\n",
       "      <td>0.334260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1988</th>\n",
       "      <td>1988</td>\n",
       "      <td>2008-08-08</td>\n",
       "      <td>0.415114</td>\n",
       "      <td>0.433814</td>\n",
       "      <td>0.416695</td>\n",
       "      <td>0.440894</td>\n",
       "      <td>0.306702</td>\n",
       "      <td>0.440894</td>\n",
       "      <td>0.566489</td>\n",
       "      <td>0.433511</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.230769</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.285</td>\n",
       "      <td>0.649</td>\n",
       "      <td>-0.9972</td>\n",
       "      <td>-0.049365</td>\n",
       "      <td>0.264766</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1989 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0        Date      Open      High       Low     Close  \\\n",
       "0              0  2016-07-01  0.966790  0.970024  0.969867  0.969145   \n",
       "1              1  2016-06-30  0.948819  0.963859  0.952488  0.967498   \n",
       "2              2  2016-06-29  0.927002  0.944437  0.930817  0.947497   \n",
       "3              3  2016-06-28  0.904440  0.919115  0.908321  0.923277   \n",
       "4              4  2016-06-27  0.918436  0.914433  0.897524  0.900373   \n",
       "...          ...         ...       ...       ...       ...       ...   \n",
       "1984        1984  2008-08-14  0.423610  0.430233  0.422020  0.430832   \n",
       "1985        1985  2008-08-13  0.432170  0.422975  0.422228  0.423779   \n",
       "1986        1986  2008-08-12  0.444822  0.435737  0.434783  0.433087   \n",
       "1987        1987  2008-08-11  0.440401  0.443018  0.441053  0.444976   \n",
       "1988        1988  2008-08-08  0.415114  0.433814  0.416695  0.440894   \n",
       "\n",
       "        Volume  Adj Close  BERT_Positive  BERT_Negative  ...  H_Aggregate  \\\n",
       "0     0.110651   0.969145       0.588598       0.411402  ...    -0.315789   \n",
       "1     0.186974   0.967498       0.585330       0.414670  ...    -0.388889   \n",
       "2     0.146990   0.947497       0.578757       0.421243  ...    -0.400000   \n",
       "3     0.155707   0.923277       0.615913       0.384087  ...     0.142857   \n",
       "4     0.195541   0.900373       0.618050       0.381950  ...    -0.263158   \n",
       "...        ...        ...            ...            ...  ...          ...   \n",
       "1984  0.227123   0.430832       0.590350       0.409650  ...    -0.083333   \n",
       "1985  0.261271   0.423779       0.578226       0.421774  ...     0.040000   \n",
       "1986  0.247828   0.433087       0.508867       0.491133  ...    -0.310345   \n",
       "1987  0.262232   0.444976       0.622814       0.377186  ...    -0.250000   \n",
       "1988  0.306702   0.440894       0.566489       0.433511  ...    -0.230769   \n",
       "\n",
       "      LM_Positive  LM_Negative  LM_Aggregate  Positive_Score  Negative_Score  \\\n",
       "0             2.0         10.0     -0.666667           0.068           0.302   \n",
       "1             2.0          9.0     -0.636364           0.087           0.297   \n",
       "2             1.0          6.0     -0.714286           0.123           0.260   \n",
       "3             2.0         11.0     -0.692308           0.143           0.172   \n",
       "4             1.0          4.0     -0.600000           0.117           0.219   \n",
       "...           ...          ...           ...             ...             ...   \n",
       "1984          0.0          3.0     -1.000000           0.121           0.227   \n",
       "1985          1.0          4.0     -0.600000           0.093           0.197   \n",
       "1986          0.0          2.0     -1.000000           0.093           0.251   \n",
       "1987          2.0          8.0     -0.600000           0.092           0.273   \n",
       "1988          0.0          5.0     -1.000000           0.066           0.285   \n",
       "\n",
       "      Neutral_Score  Compound_Score  Polarity  Subjectivity  \n",
       "0             0.631         -0.9987 -0.006564      0.316409  \n",
       "1             0.616         -0.9982  0.018968      0.377540  \n",
       "2             0.617         -0.9943  0.050125      0.387107  \n",
       "3             0.685         -0.9424  0.039465      0.329909  \n",
       "4             0.664         -0.9839 -0.006098      0.349394  \n",
       "...             ...             ...       ...           ...  \n",
       "1984          0.652         -0.9805  0.024498      0.328388  \n",
       "1985          0.709         -0.9758  0.016061      0.370301  \n",
       "1986          0.656         -0.9931 -0.036307      0.531229  \n",
       "1987          0.635         -0.9888  0.079866      0.334260  \n",
       "1988          0.649         -0.9972 -0.049365      0.264766  \n",
       "\n",
       "[1989 rows x 24 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reading the dataset\n",
    "merged_SH_new = pd.read_csv('DJIA_merged.csv')\n",
    "merged_SH_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "201e475c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0         0\n",
       "Date               0\n",
       "Open               0\n",
       "High               0\n",
       "Low                0\n",
       "Close              0\n",
       "Volume             0\n",
       "Adj Close          0\n",
       "BERT_Positive      3\n",
       "BERT_Negative      3\n",
       "MiniLM_Positive    3\n",
       "MiniLM_Negative    3\n",
       "H_Positive         3\n",
       "H_Negative         3\n",
       "H_Aggregate        3\n",
       "LM_Positive        3\n",
       "LM_Negative        3\n",
       "LM_Aggregate       3\n",
       "Positive_Score     3\n",
       "Negative_Score     3\n",
       "Neutral_Score      3\n",
       "Compound_Score     3\n",
       "Polarity           3\n",
       "Subjectivity       3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Finding if there are any missing values in the dataset\n",
    "merged_SH_new.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b0cd140",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>BERT_Positive</th>\n",
       "      <th>BERT_Negative</th>\n",
       "      <th>...</th>\n",
       "      <th>H_Aggregate</th>\n",
       "      <th>LM_Positive</th>\n",
       "      <th>LM_Negative</th>\n",
       "      <th>LM_Aggregate</th>\n",
       "      <th>Positive_Score</th>\n",
       "      <th>Negative_Score</th>\n",
       "      <th>Neutral_Score</th>\n",
       "      <th>Compound_Score</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2016-07-01</td>\n",
       "      <td>0.966790</td>\n",
       "      <td>0.970024</td>\n",
       "      <td>0.969867</td>\n",
       "      <td>0.969145</td>\n",
       "      <td>0.110651</td>\n",
       "      <td>0.969145</td>\n",
       "      <td>0.588598</td>\n",
       "      <td>0.411402</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.315789</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-0.666667</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.302</td>\n",
       "      <td>0.631</td>\n",
       "      <td>-0.9987</td>\n",
       "      <td>-0.006564</td>\n",
       "      <td>0.316409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2016-06-30</td>\n",
       "      <td>0.948819</td>\n",
       "      <td>0.963859</td>\n",
       "      <td>0.952488</td>\n",
       "      <td>0.967498</td>\n",
       "      <td>0.186974</td>\n",
       "      <td>0.967498</td>\n",
       "      <td>0.585330</td>\n",
       "      <td>0.414670</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.388889</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-0.636364</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.297</td>\n",
       "      <td>0.616</td>\n",
       "      <td>-0.9982</td>\n",
       "      <td>0.018968</td>\n",
       "      <td>0.377540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2016-06-29</td>\n",
       "      <td>0.927002</td>\n",
       "      <td>0.944437</td>\n",
       "      <td>0.930817</td>\n",
       "      <td>0.947497</td>\n",
       "      <td>0.146990</td>\n",
       "      <td>0.947497</td>\n",
       "      <td>0.578757</td>\n",
       "      <td>0.421243</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.400000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-0.714286</td>\n",
       "      <td>0.123</td>\n",
       "      <td>0.260</td>\n",
       "      <td>0.617</td>\n",
       "      <td>-0.9943</td>\n",
       "      <td>0.050125</td>\n",
       "      <td>0.387107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2016-06-28</td>\n",
       "      <td>0.904440</td>\n",
       "      <td>0.919115</td>\n",
       "      <td>0.908321</td>\n",
       "      <td>0.923277</td>\n",
       "      <td>0.155707</td>\n",
       "      <td>0.923277</td>\n",
       "      <td>0.615913</td>\n",
       "      <td>0.384087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>-0.692308</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.172</td>\n",
       "      <td>0.685</td>\n",
       "      <td>-0.9424</td>\n",
       "      <td>0.039465</td>\n",
       "      <td>0.329909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2016-06-27</td>\n",
       "      <td>0.918436</td>\n",
       "      <td>0.914433</td>\n",
       "      <td>0.897524</td>\n",
       "      <td>0.900373</td>\n",
       "      <td>0.195541</td>\n",
       "      <td>0.900373</td>\n",
       "      <td>0.618050</td>\n",
       "      <td>0.381950</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.263158</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.600000</td>\n",
       "      <td>0.117</td>\n",
       "      <td>0.219</td>\n",
       "      <td>0.664</td>\n",
       "      <td>-0.9839</td>\n",
       "      <td>-0.006098</td>\n",
       "      <td>0.349394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1984</th>\n",
       "      <td>1984</td>\n",
       "      <td>2008-08-14</td>\n",
       "      <td>0.423610</td>\n",
       "      <td>0.430233</td>\n",
       "      <td>0.422020</td>\n",
       "      <td>0.430832</td>\n",
       "      <td>0.227123</td>\n",
       "      <td>0.430832</td>\n",
       "      <td>0.590350</td>\n",
       "      <td>0.409650</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.083333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.121</td>\n",
       "      <td>0.227</td>\n",
       "      <td>0.652</td>\n",
       "      <td>-0.9805</td>\n",
       "      <td>0.024498</td>\n",
       "      <td>0.328388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1985</th>\n",
       "      <td>1985</td>\n",
       "      <td>2008-08-13</td>\n",
       "      <td>0.432170</td>\n",
       "      <td>0.422975</td>\n",
       "      <td>0.422228</td>\n",
       "      <td>0.423779</td>\n",
       "      <td>0.261271</td>\n",
       "      <td>0.423779</td>\n",
       "      <td>0.578226</td>\n",
       "      <td>0.421774</td>\n",
       "      <td>...</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.600000</td>\n",
       "      <td>0.093</td>\n",
       "      <td>0.197</td>\n",
       "      <td>0.709</td>\n",
       "      <td>-0.9758</td>\n",
       "      <td>0.016061</td>\n",
       "      <td>0.370301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1986</th>\n",
       "      <td>1986</td>\n",
       "      <td>2008-08-12</td>\n",
       "      <td>0.444822</td>\n",
       "      <td>0.435737</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.433087</td>\n",
       "      <td>0.247828</td>\n",
       "      <td>0.433087</td>\n",
       "      <td>0.508867</td>\n",
       "      <td>0.491133</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.310345</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.093</td>\n",
       "      <td>0.251</td>\n",
       "      <td>0.656</td>\n",
       "      <td>-0.9931</td>\n",
       "      <td>-0.036307</td>\n",
       "      <td>0.531229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1987</th>\n",
       "      <td>1987</td>\n",
       "      <td>2008-08-11</td>\n",
       "      <td>0.440401</td>\n",
       "      <td>0.443018</td>\n",
       "      <td>0.441053</td>\n",
       "      <td>0.444976</td>\n",
       "      <td>0.262232</td>\n",
       "      <td>0.444976</td>\n",
       "      <td>0.622814</td>\n",
       "      <td>0.377186</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.250000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-0.600000</td>\n",
       "      <td>0.092</td>\n",
       "      <td>0.273</td>\n",
       "      <td>0.635</td>\n",
       "      <td>-0.9888</td>\n",
       "      <td>0.079866</td>\n",
       "      <td>0.334260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1988</th>\n",
       "      <td>1988</td>\n",
       "      <td>2008-08-08</td>\n",
       "      <td>0.415114</td>\n",
       "      <td>0.433814</td>\n",
       "      <td>0.416695</td>\n",
       "      <td>0.440894</td>\n",
       "      <td>0.306702</td>\n",
       "      <td>0.440894</td>\n",
       "      <td>0.566489</td>\n",
       "      <td>0.433511</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.230769</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.285</td>\n",
       "      <td>0.649</td>\n",
       "      <td>-0.9972</td>\n",
       "      <td>-0.049365</td>\n",
       "      <td>0.264766</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1986 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0        Date      Open      High       Low     Close  \\\n",
       "0              0  2016-07-01  0.966790  0.970024  0.969867  0.969145   \n",
       "1              1  2016-06-30  0.948819  0.963859  0.952488  0.967498   \n",
       "2              2  2016-06-29  0.927002  0.944437  0.930817  0.947497   \n",
       "3              3  2016-06-28  0.904440  0.919115  0.908321  0.923277   \n",
       "4              4  2016-06-27  0.918436  0.914433  0.897524  0.900373   \n",
       "...          ...         ...       ...       ...       ...       ...   \n",
       "1984        1984  2008-08-14  0.423610  0.430233  0.422020  0.430832   \n",
       "1985        1985  2008-08-13  0.432170  0.422975  0.422228  0.423779   \n",
       "1986        1986  2008-08-12  0.444822  0.435737  0.434783  0.433087   \n",
       "1987        1987  2008-08-11  0.440401  0.443018  0.441053  0.444976   \n",
       "1988        1988  2008-08-08  0.415114  0.433814  0.416695  0.440894   \n",
       "\n",
       "        Volume  Adj Close  BERT_Positive  BERT_Negative  ...  H_Aggregate  \\\n",
       "0     0.110651   0.969145       0.588598       0.411402  ...    -0.315789   \n",
       "1     0.186974   0.967498       0.585330       0.414670  ...    -0.388889   \n",
       "2     0.146990   0.947497       0.578757       0.421243  ...    -0.400000   \n",
       "3     0.155707   0.923277       0.615913       0.384087  ...     0.142857   \n",
       "4     0.195541   0.900373       0.618050       0.381950  ...    -0.263158   \n",
       "...        ...        ...            ...            ...  ...          ...   \n",
       "1984  0.227123   0.430832       0.590350       0.409650  ...    -0.083333   \n",
       "1985  0.261271   0.423779       0.578226       0.421774  ...     0.040000   \n",
       "1986  0.247828   0.433087       0.508867       0.491133  ...    -0.310345   \n",
       "1987  0.262232   0.444976       0.622814       0.377186  ...    -0.250000   \n",
       "1988  0.306702   0.440894       0.566489       0.433511  ...    -0.230769   \n",
       "\n",
       "      LM_Positive  LM_Negative  LM_Aggregate  Positive_Score  Negative_Score  \\\n",
       "0             2.0         10.0     -0.666667           0.068           0.302   \n",
       "1             2.0          9.0     -0.636364           0.087           0.297   \n",
       "2             1.0          6.0     -0.714286           0.123           0.260   \n",
       "3             2.0         11.0     -0.692308           0.143           0.172   \n",
       "4             1.0          4.0     -0.600000           0.117           0.219   \n",
       "...           ...          ...           ...             ...             ...   \n",
       "1984          0.0          3.0     -1.000000           0.121           0.227   \n",
       "1985          1.0          4.0     -0.600000           0.093           0.197   \n",
       "1986          0.0          2.0     -1.000000           0.093           0.251   \n",
       "1987          2.0          8.0     -0.600000           0.092           0.273   \n",
       "1988          0.0          5.0     -1.000000           0.066           0.285   \n",
       "\n",
       "      Neutral_Score  Compound_Score  Polarity  Subjectivity  \n",
       "0             0.631         -0.9987 -0.006564      0.316409  \n",
       "1             0.616         -0.9982  0.018968      0.377540  \n",
       "2             0.617         -0.9943  0.050125      0.387107  \n",
       "3             0.685         -0.9424  0.039465      0.329909  \n",
       "4             0.664         -0.9839 -0.006098      0.349394  \n",
       "...             ...             ...       ...           ...  \n",
       "1984          0.652         -0.9805  0.024498      0.328388  \n",
       "1985          0.709         -0.9758  0.016061      0.370301  \n",
       "1986          0.656         -0.9931 -0.036307      0.531229  \n",
       "1987          0.635         -0.9888  0.079866      0.334260  \n",
       "1988          0.649         -0.9972 -0.049365      0.264766  \n",
       "\n",
       "[1986 rows x 24 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Droping rows with missing values\n",
    "merged_SH_new = merged_SH_new.dropna()\n",
    "merged_SH_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee159074",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_18716\\277736772.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  merged_SH_new['Date'] = pd.to_datetime(merged_SH_new['Date'])\n",
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_18716\\277736772.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  merged_SH_new.sort_index(ascending=False, inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>BERT_Positive</th>\n",
       "      <th>BERT_Negative</th>\n",
       "      <th>...</th>\n",
       "      <th>H_Aggregate</th>\n",
       "      <th>LM_Positive</th>\n",
       "      <th>LM_Negative</th>\n",
       "      <th>LM_Aggregate</th>\n",
       "      <th>Positive_Score</th>\n",
       "      <th>Negative_Score</th>\n",
       "      <th>Neutral_Score</th>\n",
       "      <th>Compound_Score</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Subjectivity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1988</th>\n",
       "      <td>1988</td>\n",
       "      <td>2008-08-08</td>\n",
       "      <td>0.415114</td>\n",
       "      <td>0.433814</td>\n",
       "      <td>0.416695</td>\n",
       "      <td>0.440894</td>\n",
       "      <td>0.306702</td>\n",
       "      <td>0.440894</td>\n",
       "      <td>0.566489</td>\n",
       "      <td>0.433511</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.230769</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.066</td>\n",
       "      <td>0.285</td>\n",
       "      <td>0.649</td>\n",
       "      <td>-0.9972</td>\n",
       "      <td>-0.049365</td>\n",
       "      <td>0.264766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1987</th>\n",
       "      <td>1987</td>\n",
       "      <td>2008-08-11</td>\n",
       "      <td>0.440401</td>\n",
       "      <td>0.443018</td>\n",
       "      <td>0.441053</td>\n",
       "      <td>0.444976</td>\n",
       "      <td>0.262232</td>\n",
       "      <td>0.444976</td>\n",
       "      <td>0.622814</td>\n",
       "      <td>0.377186</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.250000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-0.600000</td>\n",
       "      <td>0.092</td>\n",
       "      <td>0.273</td>\n",
       "      <td>0.635</td>\n",
       "      <td>-0.9888</td>\n",
       "      <td>0.079866</td>\n",
       "      <td>0.334260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1986</th>\n",
       "      <td>1986</td>\n",
       "      <td>2008-08-12</td>\n",
       "      <td>0.444822</td>\n",
       "      <td>0.435737</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.433087</td>\n",
       "      <td>0.247828</td>\n",
       "      <td>0.433087</td>\n",
       "      <td>0.508867</td>\n",
       "      <td>0.491133</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.310345</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.093</td>\n",
       "      <td>0.251</td>\n",
       "      <td>0.656</td>\n",
       "      <td>-0.9931</td>\n",
       "      <td>-0.036307</td>\n",
       "      <td>0.531229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1985</th>\n",
       "      <td>1985</td>\n",
       "      <td>2008-08-13</td>\n",
       "      <td>0.432170</td>\n",
       "      <td>0.422975</td>\n",
       "      <td>0.422228</td>\n",
       "      <td>0.423779</td>\n",
       "      <td>0.261271</td>\n",
       "      <td>0.423779</td>\n",
       "      <td>0.578226</td>\n",
       "      <td>0.421774</td>\n",
       "      <td>...</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.600000</td>\n",
       "      <td>0.093</td>\n",
       "      <td>0.197</td>\n",
       "      <td>0.709</td>\n",
       "      <td>-0.9758</td>\n",
       "      <td>0.016061</td>\n",
       "      <td>0.370301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1984</th>\n",
       "      <td>1984</td>\n",
       "      <td>2008-08-14</td>\n",
       "      <td>0.423610</td>\n",
       "      <td>0.430233</td>\n",
       "      <td>0.422020</td>\n",
       "      <td>0.430832</td>\n",
       "      <td>0.227123</td>\n",
       "      <td>0.430832</td>\n",
       "      <td>0.590350</td>\n",
       "      <td>0.409650</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.083333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.121</td>\n",
       "      <td>0.227</td>\n",
       "      <td>0.652</td>\n",
       "      <td>-0.9805</td>\n",
       "      <td>0.024498</td>\n",
       "      <td>0.328388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2016-06-27</td>\n",
       "      <td>0.918436</td>\n",
       "      <td>0.914433</td>\n",
       "      <td>0.897524</td>\n",
       "      <td>0.900373</td>\n",
       "      <td>0.195541</td>\n",
       "      <td>0.900373</td>\n",
       "      <td>0.618050</td>\n",
       "      <td>0.381950</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.263158</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.600000</td>\n",
       "      <td>0.117</td>\n",
       "      <td>0.219</td>\n",
       "      <td>0.664</td>\n",
       "      <td>-0.9839</td>\n",
       "      <td>-0.006098</td>\n",
       "      <td>0.349394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2016-06-28</td>\n",
       "      <td>0.904440</td>\n",
       "      <td>0.919115</td>\n",
       "      <td>0.908321</td>\n",
       "      <td>0.923277</td>\n",
       "      <td>0.155707</td>\n",
       "      <td>0.923277</td>\n",
       "      <td>0.615913</td>\n",
       "      <td>0.384087</td>\n",
       "      <td>...</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>-0.692308</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.172</td>\n",
       "      <td>0.685</td>\n",
       "      <td>-0.9424</td>\n",
       "      <td>0.039465</td>\n",
       "      <td>0.329909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2016-06-29</td>\n",
       "      <td>0.927002</td>\n",
       "      <td>0.944437</td>\n",
       "      <td>0.930817</td>\n",
       "      <td>0.947497</td>\n",
       "      <td>0.146990</td>\n",
       "      <td>0.947497</td>\n",
       "      <td>0.578757</td>\n",
       "      <td>0.421243</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.400000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-0.714286</td>\n",
       "      <td>0.123</td>\n",
       "      <td>0.260</td>\n",
       "      <td>0.617</td>\n",
       "      <td>-0.9943</td>\n",
       "      <td>0.050125</td>\n",
       "      <td>0.387107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2016-06-30</td>\n",
       "      <td>0.948819</td>\n",
       "      <td>0.963859</td>\n",
       "      <td>0.952488</td>\n",
       "      <td>0.967498</td>\n",
       "      <td>0.186974</td>\n",
       "      <td>0.967498</td>\n",
       "      <td>0.585330</td>\n",
       "      <td>0.414670</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.388889</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-0.636364</td>\n",
       "      <td>0.087</td>\n",
       "      <td>0.297</td>\n",
       "      <td>0.616</td>\n",
       "      <td>-0.9982</td>\n",
       "      <td>0.018968</td>\n",
       "      <td>0.377540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2016-07-01</td>\n",
       "      <td>0.966790</td>\n",
       "      <td>0.970024</td>\n",
       "      <td>0.969867</td>\n",
       "      <td>0.969145</td>\n",
       "      <td>0.110651</td>\n",
       "      <td>0.969145</td>\n",
       "      <td>0.588598</td>\n",
       "      <td>0.411402</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.315789</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-0.666667</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.302</td>\n",
       "      <td>0.631</td>\n",
       "      <td>-0.9987</td>\n",
       "      <td>-0.006564</td>\n",
       "      <td>0.316409</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1986 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0       Date      Open      High       Low     Close    Volume  \\\n",
       "1988        1988 2008-08-08  0.415114  0.433814  0.416695  0.440894  0.306702   \n",
       "1987        1987 2008-08-11  0.440401  0.443018  0.441053  0.444976  0.262232   \n",
       "1986        1986 2008-08-12  0.444822  0.435737  0.434783  0.433087  0.247828   \n",
       "1985        1985 2008-08-13  0.432170  0.422975  0.422228  0.423779  0.261271   \n",
       "1984        1984 2008-08-14  0.423610  0.430233  0.422020  0.430832  0.227123   \n",
       "...          ...        ...       ...       ...       ...       ...       ...   \n",
       "4              4 2016-06-27  0.918436  0.914433  0.897524  0.900373  0.195541   \n",
       "3              3 2016-06-28  0.904440  0.919115  0.908321  0.923277  0.155707   \n",
       "2              2 2016-06-29  0.927002  0.944437  0.930817  0.947497  0.146990   \n",
       "1              1 2016-06-30  0.948819  0.963859  0.952488  0.967498  0.186974   \n",
       "0              0 2016-07-01  0.966790  0.970024  0.969867  0.969145  0.110651   \n",
       "\n",
       "      Adj Close  BERT_Positive  BERT_Negative  ...  H_Aggregate  LM_Positive  \\\n",
       "1988   0.440894       0.566489       0.433511  ...    -0.230769          0.0   \n",
       "1987   0.444976       0.622814       0.377186  ...    -0.250000          2.0   \n",
       "1986   0.433087       0.508867       0.491133  ...    -0.310345          0.0   \n",
       "1985   0.423779       0.578226       0.421774  ...     0.040000          1.0   \n",
       "1984   0.430832       0.590350       0.409650  ...    -0.083333          0.0   \n",
       "...         ...            ...            ...  ...          ...          ...   \n",
       "4      0.900373       0.618050       0.381950  ...    -0.263158          1.0   \n",
       "3      0.923277       0.615913       0.384087  ...     0.142857          2.0   \n",
       "2      0.947497       0.578757       0.421243  ...    -0.400000          1.0   \n",
       "1      0.967498       0.585330       0.414670  ...    -0.388889          2.0   \n",
       "0      0.969145       0.588598       0.411402  ...    -0.315789          2.0   \n",
       "\n",
       "      LM_Negative  LM_Aggregate  Positive_Score  Negative_Score  \\\n",
       "1988          5.0     -1.000000           0.066           0.285   \n",
       "1987          8.0     -0.600000           0.092           0.273   \n",
       "1986          2.0     -1.000000           0.093           0.251   \n",
       "1985          4.0     -0.600000           0.093           0.197   \n",
       "1984          3.0     -1.000000           0.121           0.227   \n",
       "...           ...           ...             ...             ...   \n",
       "4             4.0     -0.600000           0.117           0.219   \n",
       "3            11.0     -0.692308           0.143           0.172   \n",
       "2             6.0     -0.714286           0.123           0.260   \n",
       "1             9.0     -0.636364           0.087           0.297   \n",
       "0            10.0     -0.666667           0.068           0.302   \n",
       "\n",
       "      Neutral_Score  Compound_Score  Polarity  Subjectivity  \n",
       "1988          0.649         -0.9972 -0.049365      0.264766  \n",
       "1987          0.635         -0.9888  0.079866      0.334260  \n",
       "1986          0.656         -0.9931 -0.036307      0.531229  \n",
       "1985          0.709         -0.9758  0.016061      0.370301  \n",
       "1984          0.652         -0.9805  0.024498      0.328388  \n",
       "...             ...             ...       ...           ...  \n",
       "4             0.664         -0.9839 -0.006098      0.349394  \n",
       "3             0.685         -0.9424  0.039465      0.329909  \n",
       "2             0.617         -0.9943  0.050125      0.387107  \n",
       "1             0.616         -0.9982  0.018968      0.377540  \n",
       "0             0.631         -0.9987 -0.006564      0.316409  \n",
       "\n",
       "[1986 rows x 24 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Converting the date to datetime format and sorting\n",
    "merged_SH_new['Date'] = pd.to_datetime(merged_SH_new['Date'])\n",
    "merged_SH_new.sort_index(ascending=False, inplace=True)\n",
    "merged_SH_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3b6b34",
   "metadata": {},
   "source": [
    "# Modeling and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d7ab9e",
   "metadata": {},
   "source": [
    "## LSTM, Stacked-LSTM and XGBoost with Historical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4523b0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_hist = merged_SH_new[['Open', 'High', 'Low']]\n",
    "y_hist = merged_SH_new['Close']\n",
    "\n",
    "tss = TimeSeriesSplit(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fff45784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 1s 3ms/step\n",
      "11/11 [==============================] - 1s 3ms/step\n",
      "11/11 [==============================] - 1s 3ms/step\n",
      "11/11 [==============================] - 1s 3ms/step\n",
      "11/11 [==============================] - 1s 3ms/step\n",
      "Mean MSE: 7.302153541868814e-05\n",
      "Mean MAE: 0.006586539132323857\n",
      "Mean R-squared: 0.9769724669205537\n"
     ]
    }
   ],
   "source": [
    "hist_L_mse = []\n",
    "hist_L_mae = []\n",
    "hist_L_r2 = []\n",
    "\n",
    "for train_index, test_index in tss.split(X_hist):\n",
    "    X_train, X_test = X_hist.iloc[train_index].values, X_hist.iloc[test_index].values\n",
    "    y_train, y_test = y_hist.iloc[train_index].values, y_hist.iloc[test_index].values\n",
    "\n",
    "    X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "    X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=100, input_shape=(X_train.shape[1], 1)))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    model.fit(X_train, y_train, epochs=100, batch_size=32, verbose=0)\n",
    "\n",
    "    y_LSTM_historical = model.predict(X_test)\n",
    "\n",
    "    mse_L_historical = mean_squared_error(y_test, y_LSTM_historical)\n",
    "    mae_L_historical = mean_absolute_error(y_test, y_LSTM_historical)\n",
    "    r2_L_historical = r2_score(y_test, y_LSTM_historical)\n",
    "\n",
    "    hist_L_mse.append(mse_L_historical)\n",
    "    hist_L_mae.append(mae_L_historical)\n",
    "    hist_L_r2.append(r2_L_historical)\n",
    "    \n",
    "print(f\"Mean MSE: {np.mean(hist_L_mse)}\")\n",
    "print(f\"Mean MAE: {np.mean(hist_L_mae)}\")\n",
    "print(f\"Mean R-squared: {np.mean(hist_L_r2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89139a73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 3s 7ms/step\n",
      "11/11 [==============================] - 2s 6ms/step\n",
      "11/11 [==============================] - 2s 7ms/step\n",
      "11/11 [==============================] - 3s 6ms/step\n",
      "11/11 [==============================] - 4s 7ms/step\n",
      "Mean MSE: 0.00011661247631560973\n",
      "Mean MAE: 0.008035645014178994\n",
      "Mean R-squared: 0.9634356348502763\n"
     ]
    }
   ],
   "source": [
    "hist_S_mse = []\n",
    "hist_S_mae = []\n",
    "hist_S_r2 = []\n",
    "\n",
    "for train_index, test_index in tss.split(X_hist):\n",
    "    X_train, X_test = X_hist.iloc[train_index].values, X_hist.iloc[test_index].values\n",
    "    y_train, y_test = y_hist.iloc[train_index].values, y_hist.iloc[test_index].values\n",
    "\n",
    "    X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "    X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "\n",
    "    model_S = Sequential()\n",
    "    model_S.add(LSTM(units=100, input_shape=(X_train.shape[1], 1), return_sequences=True)) \n",
    "    model_S.add(LSTM(units=100, return_sequences=True))\n",
    "    model_S.add(LSTM(units=100))\n",
    "    model_S.add(Dense(1))\n",
    "    model_S.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    model_S.fit(X_train, y_train, epochs=100, batch_size=32, verbose=0)\n",
    "\n",
    "    y_SLSTM_historical = model_S.predict(X_test)\n",
    "\n",
    "    mse_S_historical = mean_squared_error(y_test, y_SLSTM_historical)\n",
    "    mae_S_historical = mean_absolute_error(y_test, y_SLSTM_historical)\n",
    "    r2_S_historical = r2_score(y_test, y_SLSTM_historical)\n",
    "\n",
    "    hist_S_mse.append(mse_S_historical)\n",
    "    hist_S_mae.append(mae_S_historical)\n",
    "    hist_S_r2.append(r2_S_historical)\n",
    "    \n",
    "print(f\"Mean MSE: {np.mean(hist_S_mse)}\")\n",
    "print(f\"Mean MAE: {np.mean(hist_S_mae)}\")\n",
    "print(f\"Mean R-squared: {np.mean(hist_S_r2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9de63e7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean MSE: 0.005588235503231339\n",
      "Mean MAE: 0.04560065592020942\n",
      "Mean R-squared: -0.3035945024785588\n"
     ]
    }
   ],
   "source": [
    "hist_X_mse = []\n",
    "hist_X_mae = []\n",
    "hist_X_r2 = []\n",
    "\n",
    "for train_index, test_index in tss.split(X_hist):\n",
    "    X_train, X_test = X_hist.iloc[train_index].values, X_hist.iloc[test_index].values\n",
    "    y_train, y_test = y_hist.iloc[train_index].values, y_hist.iloc[test_index].values\n",
    "\n",
    "    XGBoost = xgb.XGBRegressor()\n",
    "    XGBoost = XGBoost.fit(X_train, y_train)\n",
    "    y_XGBoost_historical = XGBoost.predict(X_test)\n",
    "\n",
    "    mse_X_historical = mean_squared_error(y_test, y_XGBoost_historical)\n",
    "    mae_X_historical = mean_absolute_error(y_test, y_XGBoost_historical)\n",
    "    r2_X_historical = r2_score(y_test, y_XGBoost_historical)\n",
    "\n",
    "    hist_X_mse.append(mse_X_historical)\n",
    "    hist_X_mae.append(mae_X_historical)\n",
    "    hist_X_r2.append(r2_X_historical)\n",
    "    \n",
    "print(f\"Mean MSE: {np.mean(hist_X_mse)}\")\n",
    "print(f\"Mean MAE: {np.mean(hist_X_mae)}\")\n",
    "print(f\"Mean R-squared: {np.mean(hist_X_r2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e373b8",
   "metadata": {},
   "source": [
    "# LSTM, Stacked-LSTM and XGBoost with BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01fd010a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_B = merged_SH_new[['Open', 'High', 'Low', 'BERT_Positive', 'BERT_Negative']]\n",
    "y_B = merged_SH_new['Close']\n",
    "\n",
    "tss = TimeSeriesSplit(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a809634",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 1s 4ms/step\n",
      "11/11 [==============================] - 2s 11ms/step\n",
      "11/11 [==============================] - 1s 4ms/step\n",
      "11/11 [==============================] - 1s 5ms/step\n",
      "11/11 [==============================] - 1s 4ms/step\n",
      "Mean MSE: 8.164084680526101e-05\n",
      "Mean MAE: 0.007004523833021889\n",
      "Mean R-squared: 0.9745939832502059\n"
     ]
    }
   ],
   "source": [
    "B_L_mse = []\n",
    "B_L_mae = []\n",
    "B_L_r2 = []\n",
    "\n",
    "for train_index, test_index in tss.split(X_B):\n",
    "    X_train, X_test = X_B.iloc[train_index].values, X_B.iloc[test_index].values\n",
    "    y_train, y_test = y_B.iloc[train_index].values, y_B.iloc[test_index].values\n",
    "\n",
    "    X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "    X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=100, input_shape=(X_train.shape[1], 1)))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    model.fit(X_train, y_train, epochs=100, batch_size=32, verbose=0)\n",
    "\n",
    "    y_LSTM_B = model.predict(X_test)\n",
    "\n",
    "    mse_L_B = mean_squared_error(y_test, y_LSTM_B)\n",
    "    mae_L_B = mean_absolute_error(y_test, y_LSTM_B)\n",
    "    r2_L_B = r2_score(y_test, y_LSTM_B)\n",
    "\n",
    "    B_L_mse.append(mse_L_B)\n",
    "    B_L_mae.append(mae_L_B)\n",
    "    B_L_r2.append(r2_L_B)\n",
    "    \n",
    "print(f\"Mean MSE: {np.mean(B_L_mse)}\")\n",
    "print(f\"Mean MAE: {np.mean(B_L_mae)}\")\n",
    "print(f\"Mean R-squared: {np.mean(B_L_r2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "79a0d1ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 2s 9ms/step\n",
      "11/11 [==============================] - 2s 9ms/step\n",
      "11/11 [==============================] - 2s 9ms/step\n",
      "11/11 [==============================] - 2s 8ms/step\n",
      "11/11 [==============================] - 2s 7ms/step\n",
      "Mean MSE: 9.406686735163969e-05\n",
      "Mean MAE: 0.0075845527476320505\n",
      "Mean R-squared: 0.9732263445098468\n"
     ]
    }
   ],
   "source": [
    "B_S_mse = []\n",
    "B_S_mae = []\n",
    "B_S_r2 = []\n",
    "\n",
    "for train_index, test_index in tss.split(X_B):\n",
    "    X_train, X_test = X_B.iloc[train_index].values, X_B.iloc[test_index].values\n",
    "    y_train, y_test = y_B.iloc[train_index].values, y_B.iloc[test_index].values\n",
    "\n",
    "    X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "    X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "\n",
    "    model_S = Sequential()\n",
    "    model_S.add(LSTM(units=100, input_shape=(X_train.shape[1], 1), return_sequences=True)) \n",
    "    model_S.add(LSTM(units=100, return_sequences=True))\n",
    "    model_S.add(LSTM(units=100))\n",
    "    model_S.add(Dense(1))\n",
    "    model_S.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    model_S.fit(X_train, y_train, epochs=100, batch_size=32, verbose=0)\n",
    "\n",
    "    y_SLSTM_B = model_S.predict(X_test)\n",
    "\n",
    "    mse_S_B = mean_squared_error(y_test, y_SLSTM_B)\n",
    "    mae_S_B = mean_absolute_error(y_test, y_SLSTM_B)\n",
    "    r2_S_B = r2_score(y_test, y_SLSTM_B)\n",
    "\n",
    "    B_S_mse.append(mse_S_B)\n",
    "    B_S_mae.append(mae_S_B)\n",
    "    B_S_r2.append(r2_S_B)\n",
    "    \n",
    "print(f\"Mean MSE: {np.mean(B_S_mse)}\")\n",
    "print(f\"Mean MAE: {np.mean(B_S_mae)}\")\n",
    "print(f\"Mean R-squared: {np.mean(B_S_r2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "532d956e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean MSE: 0.005597955330121841\n",
      "Mean MAE: 0.046020046356753726\n",
      "Mean R-squared: -0.3029114927849105\n"
     ]
    }
   ],
   "source": [
    "B_X_mse = []\n",
    "B_X_mae = []\n",
    "B_X_r2 = []\n",
    "\n",
    "for train_index, test_index in tss.split(X_B):\n",
    "    X_train, X_test = X_B.iloc[train_index].values, X_B.iloc[test_index].values\n",
    "    y_train, y_test = y_B.iloc[train_index].values, y_B.iloc[test_index].values\n",
    "\n",
    "    XGBoost = xgb.XGBRegressor()\n",
    "    XGBoost = XGBoost.fit(X_train, y_train)\n",
    "    y_XGBoost_B = XGBoost.predict(X_test)\n",
    "\n",
    "    mse_X_B = mean_squared_error(y_test, y_XGBoost_B)\n",
    "    mae_X_B = mean_absolute_error(y_test, y_XGBoost_B)\n",
    "    r2_X_B = r2_score(y_test, y_XGBoost_B)\n",
    "\n",
    "    B_X_mse.append(mse_X_B)\n",
    "    B_X_mae.append(mae_X_B)\n",
    "    B_X_r2.append(r2_X_B)\n",
    "    \n",
    "print(f\"Mean MSE: {np.mean(B_X_mse)}\")\n",
    "print(f\"Mean MAE: {np.mean(B_X_mae)}\")\n",
    "print(f\"Mean R-squared: {np.mean(B_X_r2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91749cf6",
   "metadata": {},
   "source": [
    "# LSTM, Stacked-LSTM and XGBoost with MiniLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d2e8be44",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_M = merged_SH_new[['Open', 'High', 'Low', 'MiniLM_Positive', 'MiniLM_Negative']]\n",
    "y_M = merged_SH_new['Close']\n",
    "\n",
    "tss = TimeSeriesSplit(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7493bd28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 1s 4ms/step\n",
      "11/11 [==============================] - 1s 4ms/step\n",
      "11/11 [==============================] - 1s 7ms/step\n",
      "11/11 [==============================] - 1s 6ms/step\n",
      "11/11 [==============================] - 1s 5ms/step\n",
      "Mean MSE: 5.719657930620778e-05\n",
      "Mean MAE: 0.005757950836267265\n",
      "Mean R-squared: 0.9826472430999015\n"
     ]
    }
   ],
   "source": [
    "M_L_mse = []\n",
    "M_L_mae = []\n",
    "M_L_r2 = []\n",
    "\n",
    "for train_index, test_index in tss.split(X_M):\n",
    "    X_train, X_test = X_M.iloc[train_index].values, X_M.iloc[test_index].values\n",
    "    y_train, y_test = y_M.iloc[train_index].values, y_M.iloc[test_index].values\n",
    "\n",
    "    X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "    X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=100, input_shape=(X_train.shape[1], 1)))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    model.fit(X_train, y_train, epochs=100, batch_size=32, verbose=0)\n",
    "\n",
    "    y_LSTM_M = model.predict(X_test)\n",
    "\n",
    "    mse_L_M = mean_squared_error(y_test, y_LSTM_M)\n",
    "    mae_L_M = mean_absolute_error(y_test, y_LSTM_M)\n",
    "    r2_L_M = r2_score(y_test, y_LSTM_M)\n",
    "\n",
    "    M_L_mse.append(mse_L_M)\n",
    "    M_L_mae.append(mae_L_M)\n",
    "    M_L_r2.append(r2_L_M)\n",
    "    \n",
    "print(f\"Mean MSE: {np.mean(M_L_mse)}\")\n",
    "print(f\"Mean MAE: {np.mean(M_L_mae)}\")\n",
    "print(f\"Mean R-squared: {np.mean(M_L_r2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8815f43c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 2s 10ms/step\n",
      "11/11 [==============================] - 2s 17ms/step\n",
      "11/11 [==============================] - 2s 9ms/step\n",
      "11/11 [==============================] - 2s 8ms/step\n",
      "11/11 [==============================] - 2s 9ms/step\n",
      "Mean MSE: 0.00011320877334948404\n",
      "Mean MAE: 0.00877645118724922\n",
      "Mean R-squared: 0.9652055541023117\n"
     ]
    }
   ],
   "source": [
    "M_S_mse = []\n",
    "M_S_mae = []\n",
    "M_S_r2 = []\n",
    "\n",
    "for train_index, test_index in tss.split(X_M):\n",
    "    X_train, X_test = X_M.iloc[train_index].values, X_M.iloc[test_index].values\n",
    "    y_train, y_test = y_M.iloc[train_index].values, y_M.iloc[test_index].values\n",
    "\n",
    "    X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "    X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "\n",
    "    model_S = Sequential()\n",
    "    model_S.add(LSTM(units=100, input_shape=(X_train.shape[1], 1), return_sequences=True)) \n",
    "    model_S.add(LSTM(units=100, return_sequences=True))\n",
    "    model_S.add(LSTM(units=100))\n",
    "    model_S.add(Dense(1))\n",
    "    model_S.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    model_S.fit(X_train, y_train, epochs=100, batch_size=32, verbose=0)\n",
    "\n",
    "    y_SLSTM_M = model_S.predict(X_test)\n",
    "\n",
    "    mse_S_M = mean_squared_error(y_test, y_SLSTM_M)\n",
    "    mae_S_M = mean_absolute_error(y_test, y_SLSTM_M)\n",
    "    r2_S_M = r2_score(y_test, y_SLSTM_M)\n",
    "\n",
    "    M_S_mse.append(mse_S_M)\n",
    "    M_S_mae.append(mae_S_M)\n",
    "    M_S_r2.append(r2_S_M)\n",
    "    \n",
    "print(f\"Mean MSE: {np.mean(M_S_mse)}\")\n",
    "print(f\"Mean MAE: {np.mean(M_S_mae)}\")\n",
    "print(f\"Mean R-squared: {np.mean(M_S_r2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "91a03971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean MSE: 0.00571462648230791\n",
      "Mean MAE: 0.04658565167705431\n",
      "Mean R-squared: -0.3476322448874353\n"
     ]
    }
   ],
   "source": [
    "M_X_mse = []\n",
    "M_X_mae = []\n",
    "M_X_r2 = []\n",
    "\n",
    "for train_index, test_index in tss.split(X_M):\n",
    "    X_train, X_test = X_M.iloc[train_index].values, X_M.iloc[test_index].values\n",
    "    y_train, y_test = y_M.iloc[train_index].values, y_M.iloc[test_index].values\n",
    "\n",
    "    XGBoost = xgb.XGBRegressor()\n",
    "    XGBoost = XGBoost.fit(X_train, y_train)\n",
    "    y_XGBoost_M = XGBoost.predict(X_test)\n",
    "\n",
    "    mse_X_M = mean_squared_error(y_test, y_XGBoost_M)\n",
    "    mae_X_M = mean_absolute_error(y_test, y_XGBoost_M)\n",
    "    r2_X_M = r2_score(y_test, y_XGBoost_M)\n",
    "\n",
    "    M_X_mse.append(mse_X_M)\n",
    "    M_X_mae.append(mae_X_M)\n",
    "    M_X_r2.append(r2_X_M)\n",
    "    \n",
    "print(f\"Mean MSE: {np.mean(M_X_mse)}\")\n",
    "print(f\"Mean MAE: {np.mean(M_X_mae)}\")\n",
    "print(f\"Mean R-squared: {np.mean(M_X_r2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1746f49f",
   "metadata": {},
   "source": [
    "## LSTM, Stacked-LSTM and XGBoost with VADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7be39d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_V = merged_SH_new[['Open', 'High', 'Low', 'Positive_Score', 'Negative_Score', 'Neutral_Score', \n",
    "                     'Compound_Score']]\n",
    "y_V = merged_SH_new['Close']\n",
    "\n",
    "tss = TimeSeriesSplit(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6a626e88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 1s 5ms/step\n",
      "11/11 [==============================] - 1s 5ms/step\n",
      "11/11 [==============================] - 1s 5ms/step\n",
      "11/11 [==============================] - 1s 5ms/step\n",
      "11/11 [==============================] - 1s 5ms/step\n",
      "Mean MSE: 0.00015283863531523166\n",
      "Mean MAE: 0.009754417765450924\n",
      "Mean R-squared: 0.963815537301491\n"
     ]
    }
   ],
   "source": [
    "V_L_mse = []\n",
    "V_L_mae = []\n",
    "V_L_r2 = []\n",
    "\n",
    "for train_index, test_index in tss.split(X_V):\n",
    "    X_train, X_test = X_V.iloc[train_index].values, X_V.iloc[test_index].values\n",
    "    y_train, y_test = y_V.iloc[train_index].values, y_V.iloc[test_index].values\n",
    "\n",
    "    X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "    X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=100, input_shape=(X_train.shape[1], 1)))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    model.fit(X_train, y_train, epochs=100, batch_size=32, verbose=0)\n",
    "\n",
    "    y_LSTM_V = model.predict(X_test)\n",
    "\n",
    "    mse_L_V = mean_squared_error(y_test, y_LSTM_V)\n",
    "    mae_L_V = mean_absolute_error(y_test, y_LSTM_V)\n",
    "    r2_L_V = r2_score(y_test, y_LSTM_V)\n",
    "\n",
    "    V_L_mse.append(mse_L_V)\n",
    "    V_L_mae.append(mae_L_V)\n",
    "    V_L_r2.append(r2_L_V)\n",
    "    \n",
    "print(f\"Mean MSE: {np.mean(V_L_mse)}\")\n",
    "print(f\"Mean MAE: {np.mean(V_L_mae)}\")\n",
    "print(f\"Mean R-squared: {np.mean(V_L_r2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3ffcc410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 2s 11ms/step\n",
      "11/11 [==============================] - 2s 11ms/step\n",
      "11/11 [==============================] - 2s 11ms/step\n",
      "11/11 [==============================] - 2s 10ms/step\n",
      "11/11 [==============================] - 2s 11ms/step\n",
      "Mean MSE: 0.00018673967967260862\n",
      "Mean MAE: 0.010992549900125657\n",
      "Mean R-squared: 0.9465754368966308\n"
     ]
    }
   ],
   "source": [
    "V_S_mse = []\n",
    "V_S_mae = []\n",
    "V_S_r2 = []\n",
    "\n",
    "for train_index, test_index in tss.split(X_V):\n",
    "    X_train, X_test = X_V.iloc[train_index].values, X_V.iloc[test_index].values\n",
    "    y_train, y_test = y_V.iloc[train_index].values, y_V.iloc[test_index].values\n",
    "\n",
    "    X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "    X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "\n",
    "    model_S = Sequential()\n",
    "    model_S.add(LSTM(units=100, input_shape=(X_train.shape[1], 1), return_sequences=True)) \n",
    "    model_S.add(LSTM(units=100, return_sequences=True))\n",
    "    model_S.add(LSTM(units=100))\n",
    "    model_S.add(Dense(1))\n",
    "    model_S.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    model_S.fit(X_train, y_train, epochs=100, batch_size=32, verbose=0)\n",
    "\n",
    "    y_SLSTM_V = model_S.predict(X_test)\n",
    "\n",
    "    mse_S_V = mean_squared_error(y_test, y_SLSTM_V)\n",
    "    mae_S_V = mean_absolute_error(y_test, y_SLSTM_V)\n",
    "    r2_S_V = r2_score(y_test, y_SLSTM_V)\n",
    "\n",
    "    V_S_mse.append(mse_S_V)\n",
    "    V_S_mae.append(mae_S_V)\n",
    "    V_S_r2.append(r2_S_V)\n",
    "    \n",
    "print(f\"Mean MSE: {np.mean(V_S_mse)}\")\n",
    "print(f\"Mean MAE: {np.mean(V_S_mae)}\")\n",
    "print(f\"Mean R-squared: {np.mean(V_S_r2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "43512a9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean MSE: 0.0058008931756037205\n",
      "Mean MAE: 0.04736944351341513\n",
      "Mean R-squared: -0.3640780480905229\n"
     ]
    }
   ],
   "source": [
    "V_X_mse = []\n",
    "V_X_mae = []\n",
    "V_X_r2 = []\n",
    "\n",
    "for train_index, test_index in tss.split(X_V):\n",
    "    X_train, X_test = X_V.iloc[train_index].values, X_V.iloc[test_index].values\n",
    "    y_train, y_test = y_V.iloc[train_index].values, y_V.iloc[test_index].values\n",
    "\n",
    "    XGBoost = xgb.XGBRegressor()\n",
    "    XGBoost = XGBoost.fit(X_train, y_train)\n",
    "    y_XGBoost_V = XGBoost.predict(X_test)\n",
    "\n",
    "    mse_X_V = mean_squared_error(y_test, y_XGBoost_V)\n",
    "    mae_X_V = mean_absolute_error(y_test, y_XGBoost_V)\n",
    "    r2_X_V = r2_score(y_test, y_XGBoost_V)\n",
    "\n",
    "    V_X_mse.append(mse_X_V)\n",
    "    V_X_mae.append(mae_X_V)\n",
    "    V_X_r2.append(r2_X_V)\n",
    "    \n",
    "print(f\"Mean MSE: {np.mean(V_X_mse)}\")\n",
    "print(f\"Mean MAE: {np.mean(V_X_mae)}\")\n",
    "print(f\"Mean R-squared: {np.mean(V_X_r2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e71494",
   "metadata": {},
   "source": [
    "## LSTM, Stacked-LSTM and XGBoost with TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "101ff60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_T = merged_SH_new[['Open', 'High', 'Low', 'Polarity', 'Subjectivity']]\n",
    "y_T = merged_SH_new['Close']\n",
    "\n",
    "tss = TimeSeriesSplit(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "910ca732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 1s 4ms/step\n",
      "11/11 [==============================] - 15s 5ms/step\n",
      "11/11 [==============================] - 1s 6ms/step\n",
      "11/11 [==============================] - 1s 5ms/step\n",
      "11/11 [==============================] - 1s 4ms/step\n",
      "Mean MSE: 0.00011532067128977115\n",
      "Mean MAE: 0.008366121597545656\n",
      "Mean R-squared: 0.9645137296913264\n"
     ]
    }
   ],
   "source": [
    "T_L_mse = []\n",
    "T_L_mae = []\n",
    "T_L_r2 = []\n",
    "\n",
    "for train_index, test_index in tss.split(X_T):\n",
    "    X_train, X_test = X_T.iloc[train_index].values, X_T.iloc[test_index].values\n",
    "    y_train, y_test = y_T.iloc[train_index].values, y_T.iloc[test_index].values\n",
    "\n",
    "    X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "    X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=100, input_shape=(X_train.shape[1], 1)))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    model.fit(X_train, y_train, epochs=100, batch_size=32, verbose=0)\n",
    "\n",
    "    y_LSTM_T = model.predict(X_test)\n",
    "\n",
    "    mse_L_T = mean_squared_error(y_test, y_LSTM_T)\n",
    "    mae_L_T = mean_absolute_error(y_test, y_LSTM_T)\n",
    "    r2_L_T = r2_score(y_test, y_LSTM_T)\n",
    "\n",
    "    T_L_mse.append(mse_L_T)\n",
    "    T_L_mae.append(mae_L_T)\n",
    "    T_L_r2.append(r2_L_T)\n",
    "    \n",
    "print(f\"Mean MSE: {np.mean(T_L_mse)}\")\n",
    "print(f\"Mean MAE: {np.mean(T_L_mae)}\")\n",
    "print(f\"Mean R-squared: {np.mean(T_L_r2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ccb5cf0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 2s 9ms/step\n",
      "11/11 [==============================] - 2s 9ms/step\n",
      "11/11 [==============================] - 2s 8ms/step\n",
      "11/11 [==============================] - 2s 9ms/step\n",
      "11/11 [==============================] - 2s 9ms/step\n",
      "Mean MSE: 0.00016285611236659282\n",
      "Mean MAE: 0.010126279024450725\n",
      "Mean R-squared: 0.9495245431302985\n"
     ]
    }
   ],
   "source": [
    "T_S_mse = []\n",
    "T_S_mae = []\n",
    "T_S_r2 = []\n",
    "\n",
    "for train_index, test_index in tss.split(X_T):\n",
    "    X_train, X_test = X_T.iloc[train_index].values, X_T.iloc[test_index].values\n",
    "    y_train, y_test = y_T.iloc[train_index].values, y_T.iloc[test_index].values\n",
    "\n",
    "    X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "    X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "\n",
    "    model_S = Sequential()\n",
    "    model_S.add(LSTM(units=100, input_shape=(X_train.shape[1], 1), return_sequences=True)) \n",
    "    model_S.add(LSTM(units=100, return_sequences=True))\n",
    "    model_S.add(LSTM(units=100))\n",
    "    model_S.add(Dense(1))\n",
    "    model_S.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    model_S.fit(X_train, y_train, epochs=100, batch_size=32, verbose=0)\n",
    "\n",
    "    y_SLSTM_T = model_S.predict(X_test)\n",
    "\n",
    "    mse_S_T = mean_squared_error(y_test, y_SLSTM_T)\n",
    "    mae_S_T = mean_absolute_error(y_test, y_SLSTM_T)\n",
    "    r2_S_T = r2_score(y_test, y_SLSTM_T)\n",
    "\n",
    "    T_S_mse.append(mse_S_T)\n",
    "    T_S_mae.append(mae_S_T)\n",
    "    T_S_r2.append(r2_S_T)\n",
    "    \n",
    "print(f\"Mean MSE: {np.mean(T_S_mse)}\")\n",
    "print(f\"Mean MAE: {np.mean(T_S_mae)}\")\n",
    "print(f\"Mean R-squared: {np.mean(T_S_r2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "27eca247",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean MSE: 0.005736725114928993\n",
      "Mean MAE: 0.046812722288079846\n",
      "Mean R-squared: -0.3425773231245695\n"
     ]
    }
   ],
   "source": [
    "T_X_mse = []\n",
    "T_X_mae = []\n",
    "T_X_r2 = []\n",
    "\n",
    "for train_index, test_index in tss.split(X_T):\n",
    "    X_train, X_test = X_T.iloc[train_index].values, X_T.iloc[test_index].values\n",
    "    y_train, y_test = y_T.iloc[train_index].values, y_T.iloc[test_index].values\n",
    "\n",
    "    XGBoost = xgb.XGBRegressor()\n",
    "    XGBoost = XGBoost.fit(X_train, y_train)\n",
    "    y_XGBoost_T = XGBoost.predict(X_test)\n",
    "\n",
    "    mse_X_T = mean_squared_error(y_test, y_XGBoost_T)\n",
    "    mae_X_T = mean_absolute_error(y_test, y_XGBoost_T)\n",
    "    r2_X_T = r2_score(y_test, y_XGBoost_T)\n",
    "\n",
    "    T_X_mse.append(mse_X_T)\n",
    "    T_X_mae.append(mae_X_T)\n",
    "    T_X_r2.append(r2_X_T)\n",
    "    \n",
    "print(f\"Mean MSE: {np.mean(T_X_mse)}\")\n",
    "print(f\"Mean MAE: {np.mean(T_X_mae)}\")\n",
    "print(f\"Mean R-squared: {np.mean(T_X_r2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4ebcc4",
   "metadata": {},
   "source": [
    "## LSTM, Stacked-LSTM and XGBoost with LM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dd3beebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_L = merged_SH_new[['Open', 'High', 'Low', 'LM_Positive', 'LM_Negative', 'LM_Aggregate']]\n",
    "y_L = merged_SH_new['Close']\n",
    "\n",
    "tss = TimeSeriesSplit(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8f02002d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 1s 6ms/step\n",
      "11/11 [==============================] - 1s 7ms/step\n",
      "11/11 [==============================] - 1s 6ms/step\n",
      "11/11 [==============================] - 1s 5ms/step\n",
      "11/11 [==============================] - 1s 5ms/step\n",
      "Mean MSE: 0.00020809337782018441\n",
      "Mean MAE: 0.010989784535237553\n",
      "Mean R-squared: 0.938870325955197\n"
     ]
    }
   ],
   "source": [
    "L_L_mse = []\n",
    "L_L_mae = []\n",
    "L_L_r2 = []\n",
    "\n",
    "for train_index, test_index in tss.split(X_L):\n",
    "    X_train, X_test = X_L.iloc[train_index].values, X_L.iloc[test_index].values\n",
    "    y_train, y_test = y_L.iloc[train_index].values, y_L.iloc[test_index].values\n",
    "\n",
    "    X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "    X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=100, input_shape=(X_train.shape[1], 1)))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    model.fit(X_train, y_train, epochs=100, batch_size=32, verbose=0)\n",
    "\n",
    "    y_LSTM_L = model.predict(X_test)\n",
    "\n",
    "    mse_L_L = mean_squared_error(y_test, y_LSTM_L)\n",
    "    mae_L_L = mean_absolute_error(y_test, y_LSTM_L)\n",
    "    r2_L_L = r2_score(y_test, y_LSTM_L)\n",
    "\n",
    "    L_L_mse.append(mse_L_L)\n",
    "    L_L_mae.append(mae_L_L)\n",
    "    L_L_r2.append(r2_L_L)\n",
    "    \n",
    "print(f\"Mean MSE: {np.mean(L_L_mse)}\")\n",
    "print(f\"Mean MAE: {np.mean(L_L_mae)}\")\n",
    "print(f\"Mean R-squared: {np.mean(L_L_r2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6adef839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 2s 10ms/step\n",
      "11/11 [==============================] - 2s 10ms/step\n",
      "11/11 [==============================] - 2s 9ms/step\n",
      "11/11 [==============================] - 2s 10ms/step\n",
      "11/11 [==============================] - 2s 11ms/step\n",
      "Mean MSE: 0.00022184729122352032\n",
      "Mean MAE: 0.011962553324423798\n",
      "Mean R-squared: 0.9367835683456486\n"
     ]
    }
   ],
   "source": [
    "L_S_mse = []\n",
    "L_S_mae = []\n",
    "L_S_r2 = []\n",
    "\n",
    "for train_index, test_index in tss.split(X_L):\n",
    "    X_train, X_test = X_L.iloc[train_index].values, X_L.iloc[test_index].values\n",
    "    y_train, y_test = y_L.iloc[train_index].values, y_L.iloc[test_index].values\n",
    "\n",
    "    X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "    X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "\n",
    "    model_S = Sequential()\n",
    "    model_S.add(LSTM(units=100, input_shape=(X_train.shape[1], 1), return_sequences=True)) \n",
    "    model_S.add(LSTM(units=100, return_sequences=True))\n",
    "    model_S.add(LSTM(units=100))\n",
    "    model_S.add(Dense(1))\n",
    "    model_S.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    model_S.fit(X_train, y_train, epochs=100, batch_size=32, verbose=0)\n",
    "\n",
    "    y_SLSTM_L = model_S.predict(X_test)\n",
    "\n",
    "    mse_S_L = mean_squared_error(y_test, y_SLSTM_L)\n",
    "    mae_S_L = mean_absolute_error(y_test, y_SLSTM_L)\n",
    "    r2_S_L = r2_score(y_test, y_SLSTM_L)\n",
    "\n",
    "    L_S_mse.append(mse_S_L)\n",
    "    L_S_mae.append(mae_S_L)\n",
    "    L_S_r2.append(r2_S_L)\n",
    "    \n",
    "print(f\"Mean MSE: {np.mean(L_S_mse)}\")\n",
    "print(f\"Mean MAE: {np.mean(L_S_mae)}\")\n",
    "print(f\"Mean R-squared: {np.mean(L_S_r2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "67bd777f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean MSE: 0.005660140963189899\n",
      "Mean MAE: 0.04646864046347775\n",
      "Mean R-squared: -0.3184132942330832\n"
     ]
    }
   ],
   "source": [
    "L_X_mse = []\n",
    "L_X_mae = []\n",
    "L_X_r2 = []\n",
    "\n",
    "for train_index, test_index in tss.split(X_L):\n",
    "    X_train, X_test = X_L.iloc[train_index].values, X_L.iloc[test_index].values\n",
    "    y_train, y_test = y_L.iloc[train_index].values, y_L.iloc[test_index].values\n",
    "\n",
    "    XGBoost = xgb.XGBRegressor()\n",
    "    XGBoost = XGBoost.fit(X_train, y_train)\n",
    "    y_XGBoost_L = XGBoost.predict(X_test)\n",
    "\n",
    "    mse_X_L = mean_squared_error(y_test, y_XGBoost_L)\n",
    "    mae_X_L = mean_absolute_error(y_test, y_XGBoost_L)\n",
    "    r2_X_L = r2_score(y_test, y_XGBoost_L)\n",
    "\n",
    "    L_X_mse.append(mse_X_L)\n",
    "    L_X_mae.append(mae_X_L)\n",
    "    L_X_r2.append(r2_X_L)\n",
    "    \n",
    "print(f\"Mean MSE: {np.mean(L_X_mse)}\")\n",
    "print(f\"Mean MAE: {np.mean(L_X_mae)}\")\n",
    "print(f\"Mean R-squared: {np.mean(L_X_r2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4b832f",
   "metadata": {},
   "source": [
    "## LSTM, Stacked-LSTM and XGBoost with H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dd87ced0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_H = merged_SH_new[['Open', 'High', 'Low', 'H_Positive', 'H_Negative', 'H_Aggregate']]\n",
    "y_H = merged_SH_new['Close']\n",
    "\n",
    "tss = TimeSeriesSplit(n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "83215836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 1s 5ms/step\n",
      "11/11 [==============================] - 1s 5ms/step\n",
      "11/11 [==============================] - 1s 5ms/step\n",
      "11/11 [==============================] - 1s 5ms/step\n",
      "11/11 [==============================] - 1s 9ms/step\n",
      "Mean MSE: 0.00033433838548006063\n",
      "Mean MAE: 0.014103483213871369\n",
      "Mean R-squared: 0.9212301760051735\n"
     ]
    }
   ],
   "source": [
    "H_L_mse = []\n",
    "H_L_mae = []\n",
    "H_L_r2 = []\n",
    "\n",
    "for train_index, test_index in tss.split(X_H):\n",
    "    X_train, X_test = X_H.iloc[train_index].values, X_H.iloc[test_index].values\n",
    "    y_train, y_test = y_H.iloc[train_index].values, y_H.iloc[test_index].values\n",
    "\n",
    "    X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "    X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=100, input_shape=(X_train.shape[1], 1)))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    model.fit(X_train, y_train, epochs=100, batch_size=32, verbose=0)\n",
    "\n",
    "    y_LSTM_H = model.predict(X_test)\n",
    "\n",
    "    mse_L_H = mean_squared_error(y_test, y_LSTM_H)\n",
    "    mae_L_H = mean_absolute_error(y_test, y_LSTM_H)\n",
    "    r2_L_H = r2_score(y_test, y_LSTM_H)\n",
    "\n",
    "    H_L_mse.append(mse_L_H)\n",
    "    H_L_mae.append(mae_L_H)\n",
    "    H_L_r2.append(r2_L_H)\n",
    "    \n",
    "print(f\"Mean MSE: {np.mean(H_L_mse)}\")\n",
    "print(f\"Mean MAE: {np.mean(H_L_mae)}\")\n",
    "print(f\"Mean R-squared: {np.mean(H_L_r2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d566a386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 2s 10ms/step\n",
      "11/11 [==============================] - 2s 8ms/step\n",
      "11/11 [==============================] - 2s 11ms/step\n",
      "11/11 [==============================] - 2s 9ms/step\n",
      "11/11 [==============================] - 2s 8ms/step\n",
      "Mean MSE: 0.0003667491109103996\n",
      "Mean MAE: 0.013733786462779413\n",
      "Mean R-squared: 0.8822175353090816\n"
     ]
    }
   ],
   "source": [
    "H_S_mse = []\n",
    "H_S_mae = []\n",
    "H_S_r2 = []\n",
    "\n",
    "for train_index, test_index in tss.split(X_H):\n",
    "    X_train, X_test = X_H.iloc[train_index].values, X_H.iloc[test_index].values\n",
    "    y_train, y_test = y_H.iloc[train_index].values, y_H.iloc[test_index].values\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "    X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "    X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "\n",
    "    model_S = Sequential()\n",
    "    model_S.add(LSTM(units=100, input_shape=(X_train.shape[1], 1), return_sequences=True)) \n",
    "    model_S.add(LSTM(units=100, return_sequences=True))\n",
    "    model_S.add(LSTM(units=100))\n",
    "    model_S.add(Dense(1))\n",
    "    model_S.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    model_S.fit(X_train, y_train, epochs=100, batch_size=32, verbose=0)\n",
    "\n",
    "    y_SLSTM_H = model_S.predict(X_test)\n",
    "\n",
    "    mse_S_H = mean_squared_error(y_test, y_SLSTM_H)\n",
    "    mae_S_H = mean_absolute_error(y_test, y_SLSTM_H)\n",
    "    r2_S_H = r2_score(y_test, y_SLSTM_H)\n",
    "\n",
    "    H_S_mse.append(mse_S_H)\n",
    "    H_S_mae.append(mae_S_H)\n",
    "    H_S_r2.append(r2_S_H)\n",
    "    \n",
    "print(f\"Mean MSE: {np.mean(H_S_mse)}\")\n",
    "print(f\"Mean MAE: {np.mean(H_S_mae)}\")\n",
    "print(f\"Mean R-squared: {np.mean(H_S_r2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "37f8a964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean MSE: 0.005862137972876866\n",
      "Mean MAE: 0.04756121442026171\n",
      "Mean R-squared: -0.3888964720053146\n"
     ]
    }
   ],
   "source": [
    "H_X_mse = []\n",
    "H_X_mae = []\n",
    "H_X_r2 = []\n",
    "\n",
    "for train_index, test_index in tss.split(X_H):\n",
    "    X_train, X_test = X_H.iloc[train_index].values, X_H.iloc[test_index].values\n",
    "    y_train, y_test = y_H.iloc[train_index].values, y_H.iloc[test_index].values\n",
    "\n",
    "    XGBoost = xgb.XGBRegressor()\n",
    "    XGBoost = XGBoost.fit(X_train, y_train)\n",
    "    y_XGBoost_H = XGBoost.predict(X_test)\n",
    "\n",
    "    mse_X_H = mean_squared_error(y_test, y_XGBoost_H)\n",
    "    mae_X_H = mean_absolute_error(y_test, y_XGBoost_H)\n",
    "    r2_X_H = r2_score(y_test, y_XGBoost_H)\n",
    "\n",
    "    H_X_mse.append(mse_X_H)\n",
    "    H_X_mae.append(mae_X_H)\n",
    "    H_X_r2.append(r2_X_H)\n",
    "    \n",
    "print(f\"Mean MSE: {np.mean(H_X_mse)}\")\n",
    "print(f\"Mean MAE: {np.mean(H_X_mae)}\")\n",
    "print(f\"Mean R-squared: {np.mean(H_X_r2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5bbb04",
   "metadata": {},
   "source": [
    "# Chart for Actual vs Forecasted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "50941ff2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x10000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "time_axis = range(len(y_test))\n",
    "plt.plot(time_axis, y_test, label='Actual Price', color='red')\n",
    "plt.plot(time_axis, y_LSTM_M, label='Forecasted Price', color='teal')\n",
    "plt.xlabel('Day')\n",
    "plt.ylabel('Price')\n",
    "plt.title('Actual vs. Forecasted Stock Price')\n",
    "plt.legend()\n",
    "plt.figure(figsize=(15,100))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
